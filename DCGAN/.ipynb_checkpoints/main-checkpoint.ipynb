{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388f3ea1-1365-42e0-a948-064e8996f6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "sys.path.insert(0, str( Path(Path(Path(Path(Path(__file__).parent.absolute()).parent.absolute()).parent.absolute()).parent.absolute()) ))\n",
    "from Discriminator import Discriminator\n",
    "from Generator import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e9dbac-f2f8-48d7-a6e5-7022663b1e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = datasets.ImageFolder(root = '/content/drive/MyDrive/celebA/', \n",
    "                                   transform = transforms.Compose([\n",
    "                                        transforms.Resize(64),\n",
    "                                        transforms.CenterCrop(64),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5))\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21257458-1cdf-4fea-abab-160a12fbe5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_data = DataLoader(dataset = train_image, batch_size = batch_size, \n",
    "                        shuffle = True, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e647d1-aa82-4cbb-acb8-a08b53550fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all model weights should be randomly initialized from a normal distribution with mean = 0, std = 0.02\n",
    "# 그래서 reinitializs all convolutional, convolutional-transpose, and batch normalization layer\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045a2b8e-24d6-48c7-9654-54d1eb54fa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "G = Generator().to(device)\n",
    "G.apply(weight_init)\n",
    "D = Discriminator().to(device)\n",
    "D.apply(weight_init)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optim_G = torch.optim.Adam(G.parameters(), lr = 0.0001)\n",
    "optim_D = torch.optim.Adam(D.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99c849a-0abc-407a-b93c-4cf12a672677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training process\n",
    "total_epochs = 200\n",
    "total_batch = len(train_data)\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "    avg_cost = [0, 0]\n",
    "    for x, y in train_data:\n",
    "        x = x.to(device)\n",
    "\n",
    "        z = torch.randn(batch_size, 100, device = device) # noise\n",
    "        fake_img = G(z)\n",
    "        real = (torch.FloatTensor(x.size(0), 1).fill_(1.0)).to(device)\n",
    "        fake = (torch.FloatTensor(x.size(0), 1).fill_(0.0)).to(device)\n",
    "\n",
    "        # train Generator\n",
    "        optim_G.zero_grad()\n",
    "        g_loss = criterion(D(fake_img), real)\n",
    "        g_loss.backward()\n",
    "        optim_G.step()\n",
    "\n",
    "        # train Discriminator\n",
    "        optim_D.zero_grad()\n",
    "        real_loss = criterion(D(x), real)\n",
    "        fake_loss = criterion(D(fake_img), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optim_D.step()\n",
    "\n",
    "        avg_cost[0] += g_loss\n",
    "        avg_cost[1] += d_loss\n",
    "    avg_cost[0] /= total_batch\n",
    "    avg_cost[1] /= total_batch\n",
    "\n",
    "    print(f\"Epoch : {epcoh+1}, Generator : {avg_cost[0]}, Discriminator : {avg_cost[1]}\")\n",
    "\n",
    "    z = torch.randn(64, 100, device = device)\n",
    "    fake_img = G(z)\n",
    "    img_grid = make_grid(fake_img, nrow = 10, normalize = True)\n",
    "    save_image(img_grid, \"/content/drive/MyDrive/Deep Learning/GAN/GAN Result/DCGAN_result/%d.png\"%(epoch+1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
